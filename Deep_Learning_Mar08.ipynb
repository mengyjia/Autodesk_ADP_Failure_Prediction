{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn import svm\n",
    "# from sklearn import tree\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_list(csv_file):\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        your_list = list(reader)\n",
    "\n",
    "    return your_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_result = csv_to_list('Log_Data_0307/job_result11740.csv')\n",
    "keyword_in_job = csv_to_list('Log_Data_0307/keyword_in_job11740.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380503"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate maximum no of keywords in a record\n",
    "max_records = np.max(list(map(lambda x: len(x), keyword_in_job)))\n",
    "max_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_NN_format(x):\n",
    "    x = list(map(int, x)) # change 'str' to 'int'\n",
    "    \n",
    "    # change 0 to 999\n",
    "    if x == [0]:\n",
    "        x = [999]\n",
    "    \n",
    "    # padding\n",
    "    if len(x) < max_records:\n",
    "        padding = (max_records - len(x)) * [0]\n",
    "        new = padding + x\n",
    "        return new\n",
    "    else: \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform keyword_in_job\n",
    "keyword_in_job_transformed = list(map(transform_to_NN_format, keyword_in_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform job_result\n",
    "from itertools import chain\n",
    "job_result = list(chain.from_iterable(job_result)) # un-nest\n",
    "job_result_transformed  = list(map(int, job_result)) # change 'str' to 'int'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display length of keyword in job and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword_in_job_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(keyword_in_job_transformed) # this variable is in format [[l1],[l2],[l3],...] #11740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#job_result_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(job_result_transformed) # this variable is in format [1,0,-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a sample of 1000 logs and then will clean it in next step to remove logs with job result -1\n",
    "keyword_in_job_transformed_sample = keyword_in_job_transformed[:1000]\n",
    "job_result_transformed_sample = job_result_transformed[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_temp = []\n",
    "job_result_transformed_cleaned = []\n",
    "keyword_in_job_transformed_cleaned = []\n",
    "for i, value in enumerate(job_result_transformed_sample):\n",
    "    if value == -1:\n",
    "        clean_temp.append(i)\n",
    "    else:\n",
    "        job_result_transformed_cleaned.append(value)\n",
    "\n",
    "for i, value in enumerate(keyword_in_job_transformed_sample):\n",
    "    if i not in clean_temp:\n",
    "        keyword_in_job_transformed_cleaned.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_result_transformed_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keyword_in_job_transformed_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Taking a sample of 100 logs as model is taking a lot of time\n",
    "# keyword_in_job_transformed_cleaned_sample = keyword_in_job_transformed_cleaned[:100]\n",
    "# job_result_transformed_cleaned_sample = job_result_transformed_cleaned[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = keyword_in_job_transformed_cleaned[:400]\n",
    "y_train = job_result_transformed_cleaned[:400]\n",
    "X_test = keyword_in_job_transformed_cleaned[400:]\n",
    "y_test = job_result_transformed_cleaned[400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_generator(x, y=None, batch_size=50):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x= x[:n_batches*batch_size]\n",
    "    if y is not None:\n",
    "        y = y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        if y is not None:\n",
    "            yield x[ii:ii+batch_size], y[ii:ii+batch_size]\n",
    "        else:\n",
    "            yield x[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyzeLogRNN(object):\n",
    "    def __init__(self, n_words, seq_len=380503,\n",
    "                 lstm_size=256, num_layers=2, batch_size=50,\n",
    "                 learning_rate=0.0001, embed_size=100):\n",
    "        self.n_words = n_words\n",
    "        self.seq_len = seq_len\n",
    "        self.lstm_size = lstm_size \n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            tf.set_random_seed(123)\n",
    "            self.build()\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "\n",
    "    def build(self):\n",
    "        tf_x = tf.placeholder(tf.int32,\n",
    "                              shape=(self.batch_size, self.seq_len),\n",
    "                              name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.float32,\n",
    "                              shape=(self.batch_size),\n",
    "                              name='tf_y')\n",
    "        tf_keepprob = tf.placeholder(tf.float32,\n",
    "                                     name='tf_keepprob')\n",
    "        \n",
    "        embedding = tf.Variable(\n",
    "            tf.random_uniform(\n",
    "                (self.n_words, self.embed_size),\n",
    "                minval=-1, maxval=1),\n",
    "            name='embedding')\n",
    "        embed_x = tf.nn.embedding_lookup(\n",
    "            embedding, tf_x,\n",
    "            name='embeded_x')\n",
    "\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(\n",
    "            [tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(self.lstm_size),\n",
    "                output_keep_prob=tf_keepprob)\n",
    "                for i in range(self.num_layers)])\n",
    "\n",
    "        self.initial_state = cells.zero_state(\n",
    "            self.batch_size, tf.float32)\n",
    "        print('  << initial state >> ', self.initial_state)\n",
    "\n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "            cells, embed_x,\n",
    "            initial_state=self.initial_state)\n",
    "        \n",
    "        print('\\n  << lstm_output   >> ', lstm_outputs)\n",
    "        print('\\n  << final state   >> ', self.final_state)\n",
    "\n",
    "        logits = tf.layers.dense(\n",
    "            inputs=lstm_outputs[:, -1],\n",
    "            units=1, activation=None,\n",
    "            name='logits')\n",
    "\n",
    "        logits = tf.squeeze(logits, name='logits_squeezed')\n",
    "        print ('\\n  << logits        >> ', logits)\n",
    "\n",
    "        y_proba = tf.nn.sigmoid(logits, name='probabilities')\n",
    "        predictions = {\n",
    "            'probabilities': y_proba,\n",
    "            'labels' : tf.cast(tf.round(y_proba), tf.int32,\n",
    "                               name='labels')\n",
    "        }\n",
    "        print('\\n  << predictions   >> ', predictions)\n",
    "\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=tf_y, logits=logits),\n",
    "            name='cost')\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train_op = optimizer.minimize(cost, name='train_op')\n",
    "\n",
    "    def train(self, X_train, y_train, num_epochs):\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            sess.run(self.init_op)\n",
    "            iteration = 1\n",
    "            for epoch in range(num_epochs):\n",
    "                state = sess.run(self.initial_state)\n",
    "\n",
    "                for batch_x, batch_y in create_batch_generator(\n",
    "                        X_train, y_train, self.batch_size):\n",
    "                    feed = {'tf_x:0': batch_x,\n",
    "                            'tf_y:0': batch_y,\n",
    "                            'tf_keepprob:0': 0.5,\n",
    "                            self.initial_state : state}\n",
    "                    loss, _, state = sess.run(\n",
    "                        ['cost:0', 'train_op',\n",
    "                         self.final_state],\n",
    "                        feed_dict=feed)\n",
    "\n",
    "                    if iteration % 20 == 0:\n",
    "                        print(\"Epoch: %d/%d Iteration: %d \"\n",
    "                              \"| Train loss: %.5f\" % (\n",
    "                                  epoch + 1, num_epochs,\n",
    "                                  iteration, loss))\n",
    "\n",
    "                    iteration +=1\n",
    "                if (epoch+1)%10 == 0:\n",
    "                    self.saver.save(sess,\n",
    "                                    \"model/sentiment-%d.ckpt\" % epoch)\n",
    "\n",
    "    def predict(self, X_data, return_proba=False):\n",
    "        preds = []\n",
    "        with tf.Session(graph = self.g) as sess:\n",
    "            self.saver.restore(\n",
    "                sess, tf.train.latest_checkpoint('model/'))\n",
    "            test_state = sess.run(self.initial_state)\n",
    "            for ii, batch_x in enumerate(\n",
    "                    create_batch_generator(\n",
    "                        X_data, None, batch_size=self.batch_size), 1):\n",
    "                feed = {'tf_x:0' : batch_x,\n",
    "                        'tf_keepprob:0': 1.0,\n",
    "                        self.initial_state : test_state}\n",
    "                if return_proba:\n",
    "                    pred, test_state = sess.run(\n",
    "                        ['probabilities:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "                else:\n",
    "                    pred, test_state = sess.run(\n",
    "                        ['labels:0', self.final_state],\n",
    "                        feed_dict=feed)\n",
    "\n",
    "                preds.append(pred)\n",
    "\n",
    "        return np.concatenate(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 42\n",
    "sequence_length = 380503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  << initial state >>  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(50, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(50, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros:0' shape=(50, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState_1/BasicLSTMCellZeroState/zeros_1:0' shape=(50, 256) dtype=float32>))\n",
      "\n",
      "  << lstm_output   >>  Tensor(\"rnn/transpose_1:0\", shape=(50, 380503, 256), dtype=float32)\n",
      "\n",
      "  << final state   >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(50, 256) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(50, 256) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_5:0' shape=(50, 256) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_6:0' shape=(50, 256) dtype=float32>))\n",
      "\n",
      "  << logits        >>  Tensor(\"logits_squeezed:0\", shape=(50,), dtype=float32)\n",
      "\n",
      "  << predictions   >>  {'probabilities': <tf.Tensor 'probabilities:0' shape=(50,) dtype=float32>, 'labels': <tf.Tensor 'labels:0' shape=(50,) dtype=int32>}\n"
     ]
    }
   ],
   "source": [
    "rnn = AnalyzeLogRNN(n_words=n_words,\n",
    "                   seq_len=sequence_length,\n",
    "                   embed_size=100,\n",
    "                   lstm_size=256,\n",
    "                   num_layers=2,\n",
    "                   batch_size=50,\n",
    "                   learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.train(X_train, y_train, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = rnn.predict(X_test, return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rnn.predict(X_test)\n",
    "pred #predicted by RNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test # Actual label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label: 1 - success, 0 - failure\n",
    "#So the test data had three failures and two success logs\n",
    "#RNN LSTM model predicted both successes correctly, it predicted two out of three failures correctly and \n",
    "# misclassified one as success"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
